{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "15ce07131e6ac9ef2286e9dc443e97a8b7a1385e6fe0cfbd91ad33021bc29612"
   }
  },
  "interpreter": {
   "hash": "15ce07131e6ac9ef2286e9dc443e97a8b7a1385e6fe0cfbd91ad33021bc29612"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--- step_1 pdf loaded\n"
     ]
    }
   ],
   "source": [
    "# pip install pdfx\n",
    "import pdfx\n",
    "# pdf = pdfx.PDFx(\"http://europepmc.org/articles/PMC3001474?pdf=render\")\n",
    "pdf = pdfx.PDFx(\"/Users/brunoflaven/Documents/01_work/blog_articles/extending_streamlit_usage/003_99_ambitieuses_derwenai_spacy_tutorials/article_bf_2.pdf\")\n",
    "print(\"\\n--- step_1 pdf loaded\")\n",
    "# pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--- step_2 text loaded\n"
     ]
    }
   ],
   "source": [
    "text = pdf.get_text()\n",
    "# text\n",
    "print(\"\\n--- step_2 text loaded\")\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--- step_3 spacy loaded\n\n--- step_3a require cleaning spacy doc object\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load('fr_core_news_sm')\n",
    "print(\"\\n--- step_3 spacy loaded\")\n",
    "\n",
    "print(\"\\n--- step_3a require cleaning spacy doc object\")\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "# from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "# print(STOP_WORDS)\n",
    "# len(STOP_WORDS)\n",
    "\n",
    "nlp_ambitieuses_text=nlp(text)\n",
    "# print(nlp_ambitieuses_text)\n",
    "\n",
    "# print(\"Non Stop words Below that: \")\n",
    "for word in nlp_ambitieuses_text:\n",
    "    if word.is_stop==False:\n",
    "        # print(word)\n",
    "        word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--- step_4 spacy doc object into pandas dataframe\n                 0              1      2            3      4\n0           Python         Python  PROPN  proper noun  False\n1                ,              ,  PUNCT  punctuation  False\n2    Randomization  Randomization  PROPN  proper noun  False\n3                ,              ,  PUNCT  punctuation  False\n4              E2E            E2E  PROPN  proper noun  False\n..             ...            ...    ...          ...    ...\n492              ,              ,  PUNCT  punctuation  False\n493            let            let   VERB         verb  False\n494           code           code   NOUN         noun  False\n495            ...            ...  PUNCT  punctuation  False\n496              \f              \f  SPACE        space  False\n\n[497 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\n--- step_4 spacy doc object into pandas dataframe\")\n",
    "# GREAT load the spacy doc object into into a dataframe of the parsed tokens\n",
    "import pandas as pd\n",
    "\n",
    "cols = (\"text\", \"lemma\", \"POS\", \"explain\", \"stopword\")\n",
    "rows = []\n",
    "\n",
    "\n",
    "# for t in doc:\n",
    "for t in nlp_ambitieuses_text:\n",
    "    if t.is_stop==False:\n",
    "        # print(word)\n",
    "        # word\n",
    "        row = [t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
    "        rows.append(row)\n",
    "\n",
    "# TRANSFORM_1\n",
    "# We can either keep it in dictionary format or put it into a pandas dataframe\n",
    "# pd.set_option('max_colwidth',150)\n",
    "# data_df = pd.DataFrame(rows, columns=cols)\n",
    "# data_df = data_df.sort_index()\n",
    "\n",
    "# OUTPUT_1\n",
    "# data_df\n",
    "\n",
    "# TRANSFORM_2\n",
    "# Converting Dictionary to \n",
    "# Pandas Dataframe\n",
    "df = pd.DataFrame(rows)\n",
    "# OUTPUT_2\n",
    "# Print Dataframe\n",
    "# print(df)\n",
    "# df = df.dropna()\n",
    "df = df.replace(r'\\n',  ' ', regex=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}