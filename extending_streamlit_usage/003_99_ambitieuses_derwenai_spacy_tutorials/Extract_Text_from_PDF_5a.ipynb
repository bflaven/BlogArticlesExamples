{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "15ce07131e6ac9ef2286e9dc443e97a8b7a1385e6fe0cfbd91ad33021bc29612"
   }
  },
  "interpreter": {
   "hash": "15ce07131e6ac9ef2286e9dc443e97a8b7a1385e6fe0cfbd91ad33021bc29612"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--- step_1 pdf loaded\n"
     ]
    }
   ],
   "source": [
    "# pip install pdfx\n",
    "import pdfx\n",
    "# pdf = pdfx.PDFx(\"http://europepmc.org/articles/PMC3001474?pdf=render\")\n",
    "pdf = pdfx.PDFx(\"/Users/brunoflaven/Documents/01_work/blog_articles/extending_streamlit_usage/003_99_ambitieuses_derwenai_spacy_tutorials/article_bf_2.pdf\")\n",
    "print(\"\\n--- step_1 pdf loaded\")\n",
    "# pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--- step_2 text loaded\n"
     ]
    }
   ],
   "source": [
    "text = pdf.get_text()\n",
    "# text\n",
    "print(\"\\n--- step_2 text loaded\")\n",
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--- step_3 spacy loaded\n\n--- step_3a require cleaning spacy doc object\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = spacy.load('fr_core_news_sm')\n",
    "# doc is used below\n",
    "doc = nlp(text)\n",
    "print(\"\\n--- step_3 spacy loaded\")\n",
    "\n",
    "print(\"\\n--- step_3a require cleaning spacy doc object\")\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "# from spacy.lang.fr.stop_words import STOP_WORDS\n",
    "# print(STOP_WORDS)\n",
    "# len(STOP_WORDS)\n",
    "\n",
    "nlp_ambitieuses_text=nlp(text)\n",
    "# print(nlp_ambitieuses_text)\n",
    "\n",
    "# print(\"Non Stop words Below that: \")\n",
    "for word in nlp_ambitieuses_text:\n",
    "    if word.is_stop==False:\n",
    "        # print(word)\n",
    "        word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n--- step_4 spacy doc object into pandas dataframe\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              text          lemma    POS      explain  stopword\n",
       "0           Python         Python  PROPN  proper noun     False\n",
       "1                ,              ,  PUNCT  punctuation     False\n",
       "2    Randomization  Randomization  PROPN  proper noun     False\n",
       "3                ,              ,  PUNCT  punctuation     False\n",
       "4              E2E            E2E  PROPN  proper noun     False\n",
       "..             ...            ...    ...          ...       ...\n",
       "492              ,              ,  PUNCT  punctuation     False\n",
       "493            let            let   VERB         verb     False\n",
       "494           code           code   NOUN         noun     False\n",
       "495            ...            ...  PUNCT  punctuation     False\n",
       "496    \\n \\n \\n\\n\n",
       "    \\n \\n \\n\\n\n",
       "  SPACE        space     False\n",
       "\n",
       "[497 rows x 5 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>lemma</th>\n      <th>POS</th>\n      <th>explain</th>\n      <th>stopword</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Python</td>\n      <td>Python</td>\n      <td>PROPN</td>\n      <td>proper noun</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,</td>\n      <td>,</td>\n      <td>PUNCT</td>\n      <td>punctuation</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Randomization</td>\n      <td>Randomization</td>\n      <td>PROPN</td>\n      <td>proper noun</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>,</td>\n      <td>,</td>\n      <td>PUNCT</td>\n      <td>punctuation</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>E2E</td>\n      <td>E2E</td>\n      <td>PROPN</td>\n      <td>proper noun</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>492</th>\n      <td>,</td>\n      <td>,</td>\n      <td>PUNCT</td>\n      <td>punctuation</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>let</td>\n      <td>let</td>\n      <td>VERB</td>\n      <td>verb</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>code</td>\n      <td>code</td>\n      <td>NOUN</td>\n      <td>noun</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>...</td>\n      <td>...</td>\n      <td>PUNCT</td>\n      <td>punctuation</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>\\n \\n \\n\\n</td>\n      <td>\\n \\n \\n\\n</td>\n      <td>SPACE</td>\n      <td>space</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>497 rows × 5 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- step_4 spacy doc object into pandas dataframe\")\n",
    "# GREAT load the spacy doc object into into a dataframe of the parsed tokens\n",
    "import pandas as pd\n",
    "\n",
    "cols = (\"text\", \"lemma\", \"POS\", \"explain\", \"stopword\")\n",
    "rows = []\n",
    "\n",
    "# for t in doc:\n",
    "for t in nlp_ambitieuses_text:\n",
    "    if t.is_stop==False:\n",
    "        # print(word)\n",
    "        # word\n",
    "        row = [t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.is_stop]\n",
    "        rows.append(row)\n",
    "\n",
    "\n",
    "# We can either keep it in dictionary format or put it into a pandas dataframe\n",
    "pd.set_option('max_colwidth',150)\n",
    "data_df = pd.DataFrame(rows, columns=cols)\n",
    "data_df = data_df.sort_index()\n",
    "\n",
    "# OUTPUT\n",
    "data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random PERSON\nPython \n \nOrder ORG\nArthur PERSON\nSchopenhauer PERSON\nfirst ORDINAL\ntwo CARDINAL\none CARDINAL\nPO GPE\nNLP ORG\nBash GPE\nEasy PERSON\nBash PERSON\nTwo CARDINAL\nhundreds CARDINAL\nBackoffice’s ORG\nthird ORDINAL\nfourth ORDINAL\nBullshit Jobs GPE\nAl Sweigart PERSON\nDavid Graeber PERSON\n’s NORP\n"
     ]
    }
   ],
   "source": [
    "# The parsed text shows lots of characters that could be cleaned up, but for this demo, let's run named entity resolution in spaCy to extract the entities.\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  }
 ]
}